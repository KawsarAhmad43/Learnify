{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Real-World Use Case: Automated Document Organization\n",
                "\n",
                "## 1. The Problem\n",
                "We have a dump of 2,000 news articles. We want to organize them into \"Topics\" (Sports, Tech, Politics, etc.) without reading them.\n",
                "\n",
                "## 2. The Unsupervised Pipeline (LSA)\n",
                "Raw text is messy. We need a rigorous pipeline.\n",
                "1.  **Vectorizer**: Turn words into numbers (TF-IDF). This creates 10,000+ features (mostly zeros).\n",
                "2.  **SVD (LSA)**: Dimensionality reduction specifically for sparse matrices. Compresses 10,000 words into 50 \"Concepts\".\n",
                "3.  **K-Means**: Clusters the documents based on these concepts.\n",
                "\n",
                "## 3. Data\n",
                "20 Newsgroups dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.datasets import fetch_20newsgroups\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.decomposition import TruncatedSVD\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import Normalizer\n",
                "\n",
                "# 1. Load Data (Just 4 categories to make it clear)\n",
                "categories = ['rec.sport.baseball', 'sci.space', 'comp.graphics', 'talk.politics.mideast']\n",
                "dataset = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)\n",
                "print(f\"Loaded {len(dataset.data)} documents.\")\n",
                "\n",
                "# 2. Build The LSA Pipeline\n",
                "# Note: SVD output is not normalized, but KMeans likes normalized data (Cosine Similarity proxy).\n",
                "# So we add a Normalizer step.\n",
                "lsa_pipeline = Pipeline([\n",
                "    ('tfidf', TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')),\n",
                "    ('svd', TruncatedSVD(n_components=50, random_state=42)),\n",
                "    ('normalizer', Normalizer(copy=False)), # Projects to unit sphere\n",
                "    ('kmeans', KMeans(n_clusters=4, random_state=42))\n",
                "])\n",
                "\n",
                "# 3. Run it!\n",
                "print(\"Running Analysis...\")\n",
                "lsa_pipeline.fit(dataset.data)\n",
                "print(\"Done!\")\n",
                "\n",
                "# 4. Interpret Clusters\n",
                "# We need to reverse-engineer what the clusters mean.\n",
                "# We can look at the centroids in the SVD space, transform them back to TF-IDF space,\n",
                "# and see which words have the highest weights.\n",
                "\n",
                "original_space_centroids = lsa_pipeline['svd'].inverse_transform(lsa_pipeline['kmeans'].cluster_centers_)\n",
                "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
                "terms = lsa_pipeline['tfidf'].get_feature_names_out()\n",
                "\n",
                "print(\"\\nTop terms per cluster:\")\n",
                "for i in range(4):\n",
                "    print(f\"Cluster {i}:\")\n",
                "    for ind in order_centroids[i, :10]:\n",
                "        print(f\" {terms[ind]}\", end='')\n",
                "    print(\"\\n\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}