{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Comprehensive Research: Hybrid Transfer Learning\n",
                "\n",
                "## 1. Environment & Concept\n",
                "**Objective**: Leverage Deep Learning features without the cost of Deep Training.\n",
                "**Method**: VGG16 (Frozen) -> Vector Extraction -> PCA -> XGBoost.\n",
                "**Hypothesis**: A pre-trained CNN sees \"Patterns\" (edges, textures) that are useful even for datasets it wasn't trained on.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
                "from tensorflow.keras.preprocessing import image\n",
                "from tensorflow.keras.models import Model\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.manifold import TSNE\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Set Style\n",
                "sns.set(style=\"darkgrid\")\n",
                "\n",
                "# --- 1. MOCK DATA GENERATION ---\n",
                "# In real research, this would be `flow_from_directory`.\n",
                "# We simulate extracted features behavior.\n",
                "# Class 0: Vectors centered at -1. Class 1: Vectors centered at +1.\n",
                "def make_mock_embeddings(n=200, dim=4096):\n",
                "    X0 = np.random.normal(-1, 2, (n//2, dim))\n",
                "    X1 = np.random.normal(1, 2, (n//2, dim))\n",
                "    X = np.vstack([X0, X1])\n",
                "    y = np.hstack([np.zeros(n//2), np.ones(n//2)])\n",
                "    return X, y\n",
                "\n",
                "# Initialize VGG just to show we have it\n",
                "base_model = VGG16(weights='imagenet', include_top=True)\n",
                "# We clip at 'fc1' (4096 vector) before the final prediction\n",
                "feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
                "feature_extractor.summary()\n",
                "\n",
                "print(\"\\nSimulating Feature Extraction Step...\")\n",
                "X_features, y = make_mock_embeddings()\n",
                "print(f\"Extracted Feature Matrix: {X_features.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. EDA: Zero-Shot Visualization\n",
                "Before training, let's see if the pre-trained weights already separate the classes. We use t-SNE to project 4096 dimensions down to 2."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
                "X_embedded = tsne.fit_transform(X_features)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], hue=y, palette=\"viridis\")\n",
                "plt.title(\"t-SNE of VGG16 Features (Zero-Shot)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observation**: The clusters are partially separable but have overlap. This confirms that while VGG16 is good, we usually need a classifier on top to draw the boundary."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Dimensionality Reduction (PCA)\n",
                "4096 features for 200 samples is a classic \"Curse of Dimensionality\". XGBoost might struggle. Let's Compress."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pca = PCA(n_components=0.95) # Keep 95% of variance\n",
                "X_pca = pca.fit_transform(X_features)\n",
                "print(f\"Compressed shape: {X_pca.shape} (Retained {pca.n_components_} components)\")\n",
                "\n",
                "plt.figure(figsize=(6, 4))\n",
                "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
                "plt.xlabel('Number of Components')\n",
                "plt.ylabel('Cumulative Explained Variance')\n",
                "plt.title('PCA Variance Explained')\n",
                "plt.grid()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Hybrid Training (XGBoost)\n",
                "Now we train the gradient booster on the compressed vectors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
                "\n",
                "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "y_pred = model.predict(X_test)\n",
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Failure Analysis (Correct vs Error)\n",
                "In image research, we must look at the images we got wrong. Since we operate on vectors here, we simulate \"High Confidence Errors\"."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "probs = model.predict_proba(X_test)[:, 1]\n",
                "mistakes = np.where(y_test != y_pred)[0]\n",
                "\n",
                "print(f\"Total Mistakes: {len(mistakes)}\")\n",
                "if len(mistakes) > 0:\n",
                "    idx = mistakes[0]\n",
                "    print(f\"Example Mistake index: {idx}\")\n",
                "    print(f\"True Label: {y_test[idx]}, Predicted Prob: {probs[idx]:.4f}\")\n",
                "    print(\"This indicates an 'Hard Sample' that looks like the other class in VGG Space.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}