{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Real World Use Case: Deep Training Dynamics\n",
                "\n",
                "**Scenario**: You are training a very deep network (e.g., ResNet-50). The loss refuses to go down. Is it a bug?\n",
                "**Goal**: Demonstrate how **Batch Normalization** fixes the internal signal distribution, allowing deep networks to actually train."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Simulation: Signal passing through 10 layers\n",
                "layers = 10\n",
                "input_signal = np.random.randn(1000, 500) # Centered at 0, Std=1\n",
                "\n",
                "activations = {}\n",
                "\n",
                "# 1. Without Norm (Problem)\n",
                "curr = input_signal\n",
                "means = []\n",
                "stds = []\n",
                "\n",
                "for i in range(layers):\n",
                "    W = np.random.randn(500, 500) * 0.1 # Bad initialization\n",
                "    curr = np.dot(curr, W)\n",
                "    curr = np.maximum(0, curr) # ReLU\n",
                "    means.append(np.mean(curr))\n",
                "    stds.append(np.std(curr))\n",
                "\n",
                "# 2. Visualize\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.plot(means, label='Mean Activation')\n",
                "plt.plot(stds, label='Std Dev')\n",
                "plt.title(\"Signal Degradation in Deep Networks (Without BN)\")\n",
                "plt.xlabel(\"Layer Depth\")\n",
                "plt.ylabel(\"Signal Strength\")\n",
                "plt.legend()\n",
                "plt.grid()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "By Layer 10, the signal Mean and Std Deviation often collapse to near zero (Vanishing) or explode.\n",
                "Batch Normalization forces the plot above to stay stable (Mean near 0, Std near 1) across all layers, ensuring the last layer gets as strong a signal as the first layer."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}