{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Implementation: The Impact of Initialization\n",
                "\n",
                "**Goal**: Visualize how activations change with different weight initializations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# 1. Setup\n",
                "inputs = np.random.randn(1000, 500) # 1000 samples, 500 features\n",
                "hidden_size = 500\n",
                "\n",
                "def test_init(scale_factor):\n",
                "    # Initialize weights\n",
                "    W = np.random.randn(500, 500) * scale_factor\n",
                "    # Forward pass (Linear part only)\n",
                "    z = np.dot(inputs, W)\n",
                "    # Activation (Tanh)\n",
                "    a = np.tanh(z)\n",
                "    return a\n",
                "\n",
                "# 2. Compare\n",
                "# A. Too Small (0.01)\n",
                "a_small = test_init(0.01)\n",
                "# B. Too Large (1.0)\n",
                "a_large = test_init(1.0)\n",
                "# C. Xavier (Sqrt(1/n)) -> Sqrt(1/500) approx 0.045\n",
                "a_xavier = test_init(np.sqrt(1/500))\n",
                "\n",
                "# 3. Plot Histograms of Activations\n",
                "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "ax[0].hist(a_small.flatten(), bins=100, range=(-1, 1))\n",
                "ax[0].set_title(\"Small Weights: All outputs near 0\")\n",
                "\n",
                "ax[1].hist(a_large.flatten(), bins=100, range=(-1, 1))\n",
                "ax[1].set_title(\"Large Weights: Output saturated at -1 and 1\")\n",
                "\n",
                "ax[2].hist(a_xavier.flatten(), bins=100, range=(-1, 1))\n",
                "ax[2].set_title(\"Xavier: Nice Normal Distribution\")\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "*   **Small**: Tanh becomes linear near 0. Network loses power.\n",
                "*   **Large**: Tanh saturates. Gradients become 0 (Vanishing Gradient).\n",
                "*   **Xavier**: Activations are well spread, gradients will flow nicely."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}