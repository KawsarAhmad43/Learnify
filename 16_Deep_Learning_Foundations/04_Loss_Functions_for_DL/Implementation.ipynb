{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Implementation: Loss Functions from Scratch\n",
                "\n",
                "**Goal**: Implement MSE and Cross-Entropy in NumPy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# 1. Mean Squared Error (MSE)\n",
                "def mse_loss(y_true, y_pred):\n",
                "    return np.mean((y_true - y_pred) ** 2)\n",
                "\n",
                "y_true_reg = np.array([100, 50, 20])\n",
                "y_pred_reg = np.array([110, 50, 15])\n",
                "\n",
                "print(f\"MSE Loss: {mse_loss(y_true_reg, y_pred_reg)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Categorical Cross Entropy\n",
                "def cross_entropy_loss(y_true, y_pred, epsilon=1e-15):\n",
                "    # epsilon prevents log(0) which is -infinity\n",
                "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
                "    return -np.sum(y_true * np.log(y_pred)) / y_true.shape[0]\n",
                "\n",
                "# One-Hot Encoded targets\n",
                "# 3 samples, 3 classes (Cat, Dog, Bird)\n",
                "y_true_cls = np.array([\n",
                "    [1, 0, 0], # Cat\n",
                "    [0, 1, 0], # Dog\n",
                "    [0, 0, 1]  # Bird\n",
                "])\n",
                "\n",
                "# Model predictions (Softmax probs)\n",
                "y_pred_cls = np.array([\n",
                "    [0.7, 0.2, 0.1], # Confident Cat (Correct)\n",
                "    [0.1, 0.8, 0.1], # Confident Dog (Correct)\n",
                "    [0.9, 0.05, 0.05]# Confident Cat (WRONG, actually Bird)\n",
                "])\n",
                "\n",
                "print(f\"Cross Entropy Loss: {cross_entropy_loss(y_true_cls, y_pred_cls)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observation**: The loss is high because of the 3rd sample. The model predicted 'Cat' (0.9) but it was 'Bird'. \n",
                "Log loss punishes confident wrong answers severely."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}