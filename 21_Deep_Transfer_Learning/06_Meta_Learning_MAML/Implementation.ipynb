{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Implementation: MAML Inner/Outer Loop (Conceptual)\n",
                "\n",
                "**Goal**: Pseudo-code for bi-level optimization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "# 1. Mock Model Weights\n",
                "theta = torch.tensor([1.0], requires_grad=True)\n",
                "\n",
                "# 2. MAML Step\n",
                "def meta_step(task_data):\n",
                "    # --- Inner Loop ---\n",
                "    # Clone theta so we don't overwrite the original yet\n",
                "    theta_fast = theta.clone()\n",
                "    \n",
                "    # Train on Task (Support Set)\n",
                "    loss = (theta_fast - task_data)**2\n",
                "    grad = torch.autograd.grad(loss, theta_fast, create_graph=True)[0]\n",
                "    \n",
                "    # Update temporary weights\n",
                "    theta_prime = theta_fast - 0.1 * grad\n",
                "    \n",
                "    # --- Outer Loop Evaluation ---\n",
                "    # Evaluate adapted weights on Task (Query Set)\n",
                "    meta_loss = (theta_prime - task_data)**2\n",
                "    return meta_loss\n",
                "\n",
                "# 3. Run Meta-Training\n",
                "task_1_target = 5.0\n",
                "loss = meta_step(task_1_target)\n",
                "\n",
                "# Calculate Gradient w.r.t. original theta\n",
                "loss.backward()\n",
                "\n",
                "print(f\"Original Theta Grad: {theta.grad.item()}\")\n",
                "# This gradient tells us: \"How should I move theta so that ONE step of SGD moves it closer to 5.0?\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "MAML optimizes the *initialization*, not the final weights."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}