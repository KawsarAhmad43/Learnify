{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Regression Metrics Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "\n",
                "# 1. Data\n",
                "y_true = np.array([100, 200, 300, 400, 500])\n",
                "\n",
                "# Model A: Consistency small errors\n",
                "y_pred_A = np.array([110, 190, 310, 390, 510]) \n",
                "\n",
                "# Model B: One huge error\n",
                "y_pred_B = np.array([100, 200, 300, 400, 1000]) # Last one off by 500\n",
                "\n",
                "print(\"Model A MAE:\", mean_absolute_error(y_true, y_pred_A))\n",
                "print(\"Model B MAE:\", mean_absolute_error(y_true, y_pred_B))\n",
                "# Note: B's MAE is (0+0+0+0+500)/5 = 100. A's is 10."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualizing MSE vs MAE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mse_A = mean_squared_error(y_true, y_pred_A)\n",
                "mse_B = mean_squared_error(y_true, y_pred_B)\n",
                "\n",
                "print(f\"MSE A: {mse_A}\")\n",
                "print(f\"MSE B: {mse_B}\")\n",
                "\n",
                "print(f\"Ratio MAE (B/A): {100/10}\")\n",
                "print(f\"Ratio MSE (B/A): {mse_B/mse_A}\")\n",
                "# Notice how MSE explodes for Model B implies it HATES outliers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## R-Squared"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "r2_A = r2_score(y_true, y_pred_A)\n",
                "print(f\"R2 Score A: {r2_A:.4f}\") # Close to 1\n",
                "\n",
                "# Dummy model (Predicts mean)\n",
                "y_dummy = np.full(len(y_true), np.mean(y_true))\n",
                "print(f\"R2 of Mean Prediction: {r2_score(y_true, y_dummy)}\") # Should be 0"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}