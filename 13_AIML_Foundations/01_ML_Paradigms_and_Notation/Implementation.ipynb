{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ML Paradigms: Rule-Based vs Machine Learning\n",
                "\n",
                "To understand ML, we first implement a 'Rule-Based' system manually, and then see how ML differs."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Scenario: Celsius to Fahrenheit\n",
                "We know the formula is $F = C \\times 1.8 + 32$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# 1. Rule-Based Programming (Classical)\n",
                "def celsius_to_fahrenheit_rules(c):\n",
                "    return c * 1.8 + 32\n",
                "\n",
                "print(f\"100C in F (Rule): {celsius_to_fahrenheit_rules(100)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The ML Approach\n",
                "Imagine we **don't** know the formula. We only have data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data (X = Celsius, y = Fahrenheit)\n",
                "X_train = np.array([-40, -10,  0,  8, 15, 22,  38], dtype=float)\n",
                "y_train = np.array([-40,  14, 32, 46, 59, 72, 100], dtype=float)\n",
                "\n",
                "# A Simple Linear Model: y = w * x + b\n",
                "# We will try to 'learn' w and b.\n",
                "\n",
                "class SimpleLinearModel:\n",
                "    def __init__(self):\n",
                "        self.w = 1.0 # Random initialization\n",
                "        self.b = 1.0\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return self.w * x + self.b\n",
                "    \n",
                "    def train(self, X, y, epochs=500, lr=0.1):\n",
                "        # Basic Gradient Descent (Don't worry about math yet, just observe)\n",
                "        N = len(X)\n",
                "        loss_history = []\n",
                "        \n",
                "        for i in range(epochs):\n",
                "            # 1. Prediction\n",
                "            y_pred = self.forward(X)\n",
                "            \n",
                "            # 2. Error (MSE)\n",
                "            error = y_pred - y\n",
                "            loss = np.mean(error**2)\n",
                "            loss_history.append(loss)\n",
                "            \n",
                "            # 3. Gradients (Derivatives)\n",
                "            dw = (2/N) * np.dot(error, X)\n",
                "            db = (2/N) * np.sum(error)\n",
                "            \n",
                "            # 4. Update\n",
                "            self.w -= lr * dw\n",
                "            self.b -= lr * db\n",
                "            \n",
                "            if i % 100 == 0:\n",
                "                print(f\"Epoch {i}: Loss {loss:.2f}, w={self.w:.2f}, b={self.b:.2f}\")\n",
                "                \n",
                "        return loss_history\n",
                "\n",
                "# Train the model\n",
                "# Note: We normalize X slightly to help trivial training (divide by 100 not best practice but simple here)\n",
                "model = SimpleLinearModel()\n",
                "# Running on raw data might be unstable with this naive implementation, but let's try strict small LR\n",
                "loss = model.train(X_train, y_train, epochs=2000, lr=0.001)\n",
                "\n",
                "print(f\"Final Parameters -> w: {model.w:.2f}, b: {model.b:.2f}\")\n",
                "print(\"Actual Formula -> w: 1.8, b: 32\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}