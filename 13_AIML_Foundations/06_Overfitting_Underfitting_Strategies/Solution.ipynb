{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Solution: Fixing KNN Overfitting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from sklearn.datasets import load_breast_cancer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "# 1. Data\n",
                "data = load_breast_cancer()\n",
                "X, y = data.data, data.target\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
                "\n",
                "# 2. Replicate the Problem (k=1)\n",
                "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
                "knn1.fit(X_train, y_train)\n",
                "\n",
                "print(f\"K=1 Train Acc: {knn1.score(X_train, y_train):.4f}\")\n",
                "print(f\"K=1 Test Acc:  {knn1.score(X_test, y_test):.4f}\")\n",
                "print(\"Diagnosis: Extreme Overfitting! Perfect Train, Lower Test.\\n\")\n",
                "\n",
                "# 3. The Fix (Search for best K)\n",
                "train_scores = []\n",
                "test_scores = []\n",
                "k_values = range(1, 21)\n",
                "\n",
                "for k in k_values:\n",
                "    knn = KNeighborsClassifier(n_neighbors=k)\n",
                "    knn.fit(X_train, y_train)\n",
                "    train_scores.append(knn.score(X_train, y_train))\n",
                "    test_scores.append(knn.score(X_test, y_test))\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(k_values, train_scores, label='Train Acc')\n",
                "plt.plot(k_values, test_scores, label='Test Acc')\n",
                "plt.xlabel('n_neighbors (k)')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.legend()\n",
                "plt.title('Finding the Sweet Spot (Bias-Variance Tradeoff)')\n",
                "plt.grid(True)\n",
                "plt.xticks(k_values)\n",
                "plt.show()\n",
                "\n",
                "# Pick best K\n",
                "best_k = k_values[test_scores.index(max(test_scores))]\n",
                "print(f\"Best Test Accuracy found at K={best_k}: {max(test_scores):.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}